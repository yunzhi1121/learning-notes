

> 老师您好，我是Yunzhi Li。
> 这次我想汇报一下我目前做的一个方向，题目是：
> **《提升节点特征表示能力，用于可疑交易检测》**。
> 主要是围绕反洗钱图神经网络的节点特征建模做了一些改进尝试，
> 希望能更好地识别潜在的洗钱账户或者团伙行为。

【English Script】

> Hi Professor, I’m Yunzhi Li.
> I’d like to walk you through what I’ve been working on recently.
> The topic is:
> **“Improving Node Feature Representation for Suspicious Transaction Detection.”**
> It’s mainly about improving how GNNs generate node embeddings in AML settings,
> with the goal of better capturing accounts or groups involved in suspicious activity.


### ✅ Slide 2：Motivation（简化词汇 + 自然语气）

【中文逐字稿】

> 这一页我想先讲一下我关注的问题。
>
> 像 GAGNN 这种图神经网络方法，在生成节点特征的时候，通常是把一个账户的**所有历史交易**都聚合起来，做一个平均。
> 但现实中，洗钱行为很多时候是**在短时间内突然发生的**，比如几天内连续转账、拆分金额，或者集中给很多陌生账户打钱。
>
> 如果把这些近期交易跟之前所有正常交易一起平均，那种“突然的异常”很容易就被掩盖掉，模型也就难以察觉。
>
> 所以我现在的思路是：**把“最近的交易行为”单独拿出来建模**，同时保留历史的整体行为。
>
> 让模型既能看到这个账户平时的行为习惯，也能发现它最近有没有突然“活跃”起来，这样判断会更准确。

---

【English Script（简化词汇）】

> On this slide, I’d like to explain the main problem I’m focusing on.
>
> In models like GAGNN, node features are usually built by taking the **average of all past transactions**.
> But in reality, money laundering often happens in **short bursts** — for example, many small transfers or sudden activity within just a few days.
>
> When we mix recent and older transactions all together, those short-term spikes can **easily get lost**, and the model may miss them.
>
> So my idea is to **separate recent transactions from historical ones**, and use both when creating node features.
>
> This way, the model can understand what the account usually looks like, and also notice if anything **suddenly changes** in the recent period.


好的，以下是**Slide 3：My Design（方法页）**的中英文逐字稿，已做**词汇简化 + 语气自然化处理**，更适合与老师对话时流畅讲解。

---

### ✅ Slide 3：My Design（简化版）

【中文逐字稿】

> 接下来我想讲一下我提出的方法。
>
> 在原始的 GAGNN 里面，一个节点的特征是通过把它所有历史交易做平均得到的。
> 但像我刚才说的，如果洗钱是在短时间内突然爆发的，**平均就会把这些异常冲淡掉**。
>
> 所以我提出了一个**双通道的特征生成结构**。
>
> * 一个是**全局通道**：像原来的方法一样，用所有历史交易来提取长期行为。
> * 另一个是**局部通道**：只看“最近一小段时间”内的交易，比如最近 1 天，用来捕捉近期的异常。
>
> 最后，我不是把它们再平均，而是**把这两个特征拼接在一起**，让后面的模型能同时用到长期信息和短期信息。
>
> 这样做的好处是：**不会互相干扰**，而是让模型自己去学，哪个通道在当前这个账户上更重要。

---

【English Script（简化版）】

> Now I’ll explain the method I designed.
>
> In the original GAGNN, node features are created by **averaging all past transactions**.
> But as I mentioned earlier, if suspicious activity happens suddenly, this average can **hide those recent changes**.
>
> So I propose a **dual-channel feature generator**.
>
> * One channel is **global** — it uses all historical transactions, just like the original method, to capture long-term behavior.
> * The other is **local** — it only looks at the **recent time window**, like the past 1 day, to focus on short-term anomalies.
>
> Then, instead of averaging again, I **concatenate** the two features, so that the model can use both global and local signals together.
>
> The key idea is that this keeps them **separate but complete**, and lets the model learn which part matters more in each case.


当然可以，以下是你这张方法图的**详细描述（中英文对照）**，可用于讲解或PPT备注中，既清楚说明流程，也突出了设计思路。

---

### ✅ 方法图详细讲解（中文逐字稿）

> 这张图展示了我提出的**双通道节点特征生成结构**的整体流程。
>
> 整体分为上下两个通道：上面是**全局通道**，下面是**局部通道**。
>
> * 在左侧，每一个圆圈代表一个账户，箭头表示交易行为。中间的黄色节点是我们要建模的目标账户。
>
> * 在**全局通道**中，我们收集它过去所有的交易记录，用这些交易的特征组成一个矩阵，然后做平均操作，得到一个全局交易特征向量（绿色的）。这反映的是该账户的**长期行为模式**。
>
> * 同样地，在**局部通道**中，我们只选取**最近一段时间的交易**，例如过去 1 天的记录，构成另一个交易矩阵，经过平均后得到一个“近期行为特征”（橙色的），用于表示账户近期是否有异常波动。
>
> * 然后，这两个通道的特征分别输入到一个 MLP（多层感知机）中做非线性变换，提升表达能力。
>
> * 最后，我将两个通道的输出**进行拼接**，得到一个融合后的节点表示，作为最终的输入特征传递到下游的检测模块中。
>
> 这个方法的关键点是：**保留长期与短期的独立特征信息，不做混合平均，让模型自己学习如何使用这两个方向的信息。**

---

### ✅ Detailed Explanation in English

> This diagram shows the overall workflow of my **dual-channel node feature generator**.
>
> There are two branches: the **global channel** at the top, and the **local (recent) channel** at the bottom.
>
> * On the left side, each circle represents an account, and the arrows indicate transaction relationships. The yellow node in the center is the account we are modeling.
>
> * In the **global channel**, I collect all historical transactions related to the target node. The features of those transactions form a matrix, which is then averaged to obtain a global feature vector (in green).
>   This reflects the **long-term behavior** of the account.
>
> * In the **local channel**, I select only the **most recent transactions** — for example, those within the past 1 day — and build a similar feature matrix. After aggregation, this gives the **recent behavior vector** (in orange), which highlights any sudden changes or bursts.
>
> * Each feature vector is then passed through a separate MLP (Multi-Layer Perceptron) to increase representation power.
>
> * Finally, I **concatenate** the two transformed feature vectors to form a single combined node embedding, which will be fed into the downstream prediction module.


好的，以下是\*\*Slide 4：Technical Details（技术细节）\*\*的逐字稿，已根据你的风格做了以下调整：

* 语气更自然、贴近老师沟通场景
* 复杂词（如 unstable、contamination、fusion）已替换为更易懂表达
* 每一段落都控制在可口述长度

---

### ✅ Slide 4：Technical Details（简化 + 自然语气版）

【中文逐字稿】

> 这一页我想补充一下我在设计上的几个细节考虑。
>
> 首先，有一个问题是：**为什么我不直接用加权平均或者注意力机制**来融合全局特征和局部特征？
>
> 我的实验观察是：
>
> * **加权平均**虽然看起来可以融合两个信息，但它会把长期行为和近期行为“混在一起”，这样一来，两个特征可能都会被干扰，模型很难分清哪一部分代表异常。
> * **注意力机制**在理论上确实更灵活，但它对数据量比较敏感。尤其是一些账户在近期交易比较少的时候，注意力学出来的权重会非常不稳定，容易出现噪声。
>
> 所以相比之下，我觉得**拼接（concatenation）更简单有效**。它可以把两部分信息分开保留下来，让模型自己去学习哪个更有用。
>
> 第二个问题是“怎么定义最近交易”？我目前设的是**1天的窗口**，这个长度是我参考了原论文数据的时间分布，并做了网格搜索试出来的。
> 后面我也计划比较不同时间窗口，比如 3 天、7 天，看看哪个更能反映异常模式。
>
> 最后，我这个模块是作为一个前置的特征增强结构，加在 GAGNN 原始模型的社区检测模块之前（也就是 GAT + eMRF 之前）。
> 所以它不会影响模型的结构，只是在输入端做增强。

---

【English Script（简化自然表达）】

> This slide explains some key design choices in my method.
>
> First, a common question is:
> **Why not use weighted average or attention** to combine global and recent features?
>
> From what I’ve tested:
>
> * **Weighted average** blends the two signals too early, and that can cause confusion — the model can’t tell which part is from stable history, and which part is a recent anomaly.
> * **Attention** is flexible in theory, but it becomes unstable when a node has very few recent transactions. The attention weights then become noisy or meaningless.
>
> So, I find that using **concatenation** is a simpler and safer choice. It keeps both parts separate and lets the model learn how to use them.
>
> Second, how do I define “recent”?
> I currently use a **1-day window**, based on the data distribution and grid search.
> I also plan to compare different windows — like 3 days or 7 days — to see which one better captures suspicious behavior.
>
> Lastly, this feature module is added **before** the community detection part of GAGNN (that’s the GAT + eMRF module).
> So it doesn’t change the model structure — it just improves the quality of node features going in.



### ✅ Slide 5：Case Example（简化 + 实用表达）

【中文逐字稿】

> 这一页我想用一个具体的账户案例来说明，为什么我们需要引入“时间敏感”的节点特征。
>
> 这个账户的 ID 是 **800AEAC00**，我们可以看到它在 9 月 8 日这一天的交易量**突然大幅增加**。
>
> 左边是它每天的交易笔数，之前基本都在 2 到 3 笔，但到了 9 月 8 号，它一下子做了 **17 笔交易**。
> 相比于前几天的平均交易数，这个账户在那天的交易量上涨了大概 **3.6 倍**。
>
> 右边是它的交易子图，也就是它当天和其他账户的转账关系图。我们能看到它在这一天**突然和很多账户建立连接**，形成一个辐射状的结构。
> 图中**红色的边表示被标记为洗钱交易**，而绿色是正常的。可以看到大部分的边都是红色的，说明这一天它的行为确实很异常。
>
> 但如果我们把这 10 天的交易都平均处理，那这一天的爆发行为就会被“平滑掉”，模型可能完全察觉不到。
>
> 所以，我的方法中加入了**局部通道**，专门提取近期的行为特征，像这种短期内的突变行为就能被更容易地捕捉到。

---

【English Script（简化 + 自然语气）】

> Here I’d like to walk through a real example to show why we need **time-sensitive node features**.
>
> This is account **800AEAC00**, and we can see that on **September 8**, its activity suddenly spiked.
>
> On the left, we see the daily transaction count.
> Most days it made only 2 or 3 transactions, but on Sept. 8, it made **17** — that’s more than **3.6 times** the average of the previous days.
>
> On the right is its transaction subgraph — showing which accounts it interacted with.
> The **red edges** are marked as laundering transactions, and the **green ones** are normal.
> As we can see, most of the outgoing transfers on September 8 were suspicious — and the structure is kind of **star-shaped**, meaning it suddenly interacted with many new nodes.
>
> If we simply average the 10 days of activity, this spike would be flattened out, and the model might miss it completely.
>
> But with my method, the **local channel explicitly captures recent activity**, so bursts like this are more likely to be noticed by the model.



### ✅ Slide 6：Planned Experiment Setup（简化 + 进度感）

【中文逐字稿】

> 接下来是我目前已经准备好的实验设计部分。
>
> 现在我已经跑通了原始的 GAGNN 模型，下一步会对比三组不同的节点特征方案：
>
> * 第一组是**Baseline**，也就是原始的 GAGNN，它只使用所有历史交易的平均特征；
> * 第二组是只用**近期窗口内的交易**，大概是 1 天内的交易，来构建节点特征；
> * 第三组是我提出的方案，**拼接全局和近期特征**，也就是双通道结构。
>
> 实验将使用的是 **IBM Transactions for AML** 数据集，它虽然是合成数据，但包含了明确标注的可疑交易和账户，非常适合用于反洗钱任务的评估。
>
> 我会采用两个主要的评估指标：
>
> * 第一个是 **Precision\@K**，我们重点关注 Top 1%、5%、10% 的结果，看能否精准抓住最可疑的账户；
> * 第二个是 **AUC**，也就是模型整体排序的效果。
>
> 我的目标是通过这个设计，对比验证：**引入时间维度的特征拼接是否真的能提升识别团伙洗钱的能力。**

---

【English Script（简化 + 语气自然）】

> Now I’d like to explain my current experiment setup.
>
> At this point, I’ve already reproduced the original GAGNN model, and I’m preparing to compare three different feature strategies:
>
> * The first is the **Baseline**, which uses only global average features from all past transactions.
> * The second uses **only recent transactions** within a fixed window — for example, one day — to build node features.
> * The third is **my method**, which concatenates both global and recent features using a dual-channel design.
>
> I’ll be using the **IBM Transactions for AML** dataset.
> Although it’s synthetic, it has clearly labeled suspicious activities and accounts, which makes it well-suited for evaluating AML detection models.
>
> For evaluation, I’ll focus on two metrics:
>
> * **Precision\@K**, especially for Top 1%, 5%, and 10%, to see how well the model identifies the most suspicious nodes.
> * And **AUC**, to measure the overall ranking quality of the model’s predictions.
>
> The key goal is to verify:
> **Does adding time-aware features actually improve the model’s ability to detect laundering behavior — especially group-based activity?**




### ✅ Slide 7：Conclusion & Next Steps（自然 + 紧迫感）

【中文逐字稿】

> 最后我做一个简单的总结和接下来的计划安排。
>
> 这次工作主要解决的是**现有反洗钱 GNN 模型缺乏时间敏感性**的问题。
>
> 我提出了一个**双通道的节点特征生成方法**，把账户的长期行为和近期交易分开建模，通过拼接的方式融合，
> 避免了平均聚合带来的信息丢失，让模型能更好地识别短期爆发式的洗钱行为。
>
> 截止目前，我已经完成了方法设计、模块实现，并成功复现了原始 GAGNN 的结果，下一步是集中进行实验验证。
>
> 实验会使用 IBM 的反洗钱数据集，评估不同特征方案在 Precision\@K 和 AUC 上的表现。
> 我也计划比较不同的时间窗口长度，比如 1 天、3 天、7 天，看看粒度对识别结果有没有影响。
>
> 由于现在距离论文截止还有不到 3 周，时间上会比较紧张，我会优先完成消融实验和对比分析，
> 如果时间允许，也会尝试加入**基于注意力的时间动态融合方法**作为扩展。
>
> 我的目标是交付一份**聚焦问题、方法清晰、具有时序创新点**的工作，感谢老师的指导！

---

【English Script（简化自然表达 + 紧迫感）】

> I’d like to give a quick summary and outline the next steps.
>
> This work focuses on addressing a gap in existing AML GNN models —
> namely, their **lack of temporal sensitivity** when generating node features.
>
> I proposed a **dual-channel feature generator** that models long-term and recent behaviors separately, and combines them via concatenation.
> This avoids the information loss caused by averaging and makes the model more aware of **short-term spikes** that often indicate laundering.
>
> So far, I’ve completed the design, implemented the module, and reproduced the original GAGNN results.
> The next step is to run the full set of experiments.
>
> I’ll be using the IBM AML dataset to evaluate how different feature strategies perform in terms of Precision\@K and AUC.
> I also plan to test different time windows — such as 1-day, 3-day, and 7-day — to see how temporal granularity affects detection.
>
> Since there are **less than 3 weeks left** before the paper deadline, I’ll prioritize completing the ablation studies and key comparisons.
> If time allows, I’d like to try using attention **after feature extraction**, to let the model learn how to balance global and recent information — even though attention doesn’t work well on sparse transactions, it might still help at the fusion stage.
>
> Overall, my goal is to deliver a focused and well-motivated project with a clear temporal contribution.
> Thank you very much for your time and feedback!









